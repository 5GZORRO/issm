# Copyright 2020 - 2021 IBM Corporation

# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at

# http://www.apache.org/licenses/LICENSE-2.0

# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

###############################################################################
#
# Business flow Scenario UC 1.2:
# ==============================
#
# Scenario UC1.2 deals with instantiating a 5G UPF in stakeholder premises where it is
# assumed that 5G core already runs there. It also deals with extending the service
# by instantiating another 5G UPF in a 3rd party domain where that UPF is registered to stakeholder's core
#
# Instantiate. Instantiation of an already purshased 5G UPF SW offer
#
# Parameters:
#
#     product_id: the id of the UPF offer to instantiate (e.g. 3e922f24-01ec-4f83-8328-b69dc9ab8f8e)
#     service_owner: stakeholder name (e.g. operator-a)
#     elma_url: domain license agent
#     catalogue_url: domain calatlogue service
#
# Steps:
#
# * Retrieve from domain's catalogue (given product_id):
#       - service_owner (stakeholder)
#       - Image registry (UPF image)
#       - DID
#
# * Orchestrate the instantiation of the SW at the stakeholder premises and return the instance_id
#
# ==============================================================================
#
# Scaleout. Scaleout of an existing service - into a best 3rd party edge premises
#           that fulfils service's sizing demands
#
# Parameters:
#
#     product_id: the id of the UPF offer to scaleout (e.g. 3e922f24-01ec-4f83-8328-b69dc9ab8f8e)
#     service_owner: stakeholder name (e.g. operator-a)
#     place: the location of where we would like to scaleout (PO TMF format)
#     elma_url: domain license agent
#     catalogue_url: domain calatlogue service
#     trmf_url: domain trmf service
#
#
# Steps:
#
# * Retrieve from domain's catalogue (given product_id):
#       - CPU, RAM, Storage
#       - Image registry (UPF image)
#       - DID
#
# * Build sizing intent out from the above extracted data
#
# * Discover IaaS Edge resource offers based on requirements that include
#     - location
#     - sizings
#     e.g. for a discovery query: "storage 96 GB 2730 MB of ram edge, barcelona spain"
#
# * Send offers to ISSM-O
#
# * Retrieve best resource offer from ISSM-O
#
# * Aquire IaaS resource offer from marketplace and notify TRMF
#
#   - UPF is deployed into 3rd party domain and get connected to stakeholder's
#     running core
# 
###############################################################################

apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: uc1-2-submit
spec:
  templates:
  - name: handle-submit
    # Entry point of the scenario
    steps:
    - - name: handle-instantiate
        template: handle-submit-instantiate
        when: "{{workflow.parameters.operation}} == \"instantiate\""

    - - name: handle-scaleout
        template: handle-submit-scaleout
        when: "{{workflow.parameters.operation}} == \"scaleout\""

  - name: handle-submit-instantiate
    steps:
    # Branching point according to internal state
    # of the transaction
    steps:
    - - name: handle-new-intent-instantiate
        template: handle-new-intent-instantiate
        when: "{{workflow.parameters.sub_operation}} == \"new_intent\""

    - - name: handle-orchestration-instantiate
        templateRef:
          name: uc1-2-orchestration-template
          template: orchestration-instantiate
        when: "{{workflow.parameters.sub_operation}} == \"submit_orchestration\""

  - name: handle-submit-scaleout
    # Branching point according to internal state
    # of the transaction
    steps:
    - - name: handle-new-intent
        template: handle-new-intent
        when: "{{workflow.parameters.sub_operation}} == \"new_intent\""

    - - name: handle-best-offers
        template: handle-best-offers
        when: "{{workflow.parameters.sub_operation}} == \"submit_bp\""

    - - name: handle-orchestration
        templateRef:
          name: uc1-2-orchestration-template
          template: orchestration-scaleout
        when: "{{workflow.parameters.sub_operation}} == \"submit_orchestration\""


  - name: handle-new-intent-instantiate
    dag:
      tasks:
      - name: get-product-offer-from-catalog
        template: get-product-offer-from-catalog
        arguments:
          parameters:
          - name: product_id
            value: "{{workflow.parameters.product_id}}"

      - name: trigger-orchestration-instantiate
        dependencies: [get-product-offer-from-catalog]
        template: trigger-orchestration
        arguments:
          parameters:
          - name: resource_owner
            # stakeholder name for the orch request to be routed to
            value: "{{workflow.parameters.service_owner}}"
          - name: product_DID
            value: "{{tasks.get-product-offer-from-catalog.outputs.parameters.did}}"


  - name: handle-new-intent
    dag:
      tasks:
      - name: get-product-offer-from-catalog
        template: get-product-offer-from-catalog
        arguments:
          parameters:
          - name: product_id
            value: "{{workflow.parameters.product_id}}"

      - name: build-intent-query
        dependencies: [get-product-offer-from-catalog]
        template: build-intent-query
        arguments:
          parameters:
          - name: place
            value: "{{workflow.parameters.place}}"
          - name: cpu_max
            value: "{{tasks.get-product-offer-from-catalog.outputs.parameters.cpu_max}}"
          - name: mem_max
            value: "{{tasks.get-product-offer-from-catalog.outputs.parameters.mem_max}}"
          - name: mem_unit
            value: "{{tasks.get-product-offer-from-catalog.outputs.parameters.mem_unit}}"
          - name: storage_max
            value: "{{tasks.get-product-offer-from-catalog.outputs.parameters.storage_max}}"
          - name: storage_unit
            value: "{{tasks.get-product-offer-from-catalog.outputs.parameters.storage_unit}}"

      - name: srds-service
        template: srds-service
        dependencies: [build-intent-query]
        arguments:
          parameters:
          - name: service_ip
            value: "{{workflow.parameters.discovery_ip}}"
          - name: service_port
            value: "{{workflow.parameters.discovery_port}}"
          - name: intent_query
            value: "{{tasks.build-intent-query.outputs.result}}"
          - name: place
            # HACK UNTIL SRSD IS FIXED
            value: "{{workflow.parameters.place}}"

      - name: send-resouces-to-optimizer
        # publish discovered resources for the optimizer to consume
        dependencies: [srds-service]
        templateRef:
          name: workflow-base
          template: publish-on-kafka
        arguments:
          parameters:
          - name: data
            value: |
              { "transaction_uuid": "{{workflow.name}}", "topic": "issm-in-{{workflow.parameters.service_owner}}", 
                "resources": {{tasks.srds-service.outputs.result}}, "scenario": "{{workflow.parameters.scenario}}",
                "operation": "{{workflow.parameters.operation}}", "sub_operation": "submit_bp",
                "service_owner": "{{workflow.parameters.service_owner}}", "elma_url": "{{workflow.parameters.elma_url}}",
                "product_id": "{{workflow.parameters.product_id}}",
                "catalogue_url": "{{workflow.parameters.catalogue_url}}", "trmf_url": "{{workflow.parameters.trmf_url}}",
                "service_id": "{{workflow.parameters.service_id}}"
              }
          - name: kafka_topic
            value: issm-optimizer

  - name: handle-best-offers
    dag:
      tasks:
      - name: get-product-offer-from-catalog
        template: get-product-offer-from-catalog
        arguments:
          parameters:
          - name: product_id
            value: "{{workflow.parameters.product_id}}"

      - name: handle-best-offers
        # this step is mainly for pretty print
        templateRef:
          name: workflow-base
          template: jq-script
        arguments:
          parameters:
          - name: json_str
            value: "{{workflow.parameters.resources}}"
          - name: jq_query
            value: '.'

      - name: loop-best-offers-resource
        # loop through 'resource' type offers
        dependencies: [handle-best-offers, get-product-offer-from-catalog]
        template: loop-best-offers
        arguments:
          parameters:
          - name: best_offer
            value: "{{item}}"
          - name: product_DID
            value: "{{tasks.get-product-offer-from-catalog.outputs.parameters.did}}"
        withParam: "{{workflow.parameters.resources}}"

  - name: loop-best-offers
    inputs:
      parameters:
      - name: best_offer
      - name: product_DID
    dag:
      tasks:
      - name: resource-service-owner
        templateRef:
          name: workflow-base
          template: jq-script
        arguments:
          parameters:
          - name: json_str
            value: "{{inputs.parameters.best_offer}}"
          - name: jq_query
            value: '.offer_object.productSpecification.relatedParty[0].name'

      - name: process-mno-name
        dependencies: [resource-service-owner]
        templateRef:
          name: workflow-base
          template: correct-mno-name
        arguments:
          parameters:
          - name: mno_name
            value: "{{tasks.resource-service-owner.outputs.result}}"

      - name: resource-did
        templateRef:
          name: workflow-base
          template: jq-script
        arguments:
          parameters:
          - name: json_str
            value: "{{inputs.parameters.best_offer}}"
          - name: jq_query
            value: '.offer_did'

      - name: acquire
        dependencies: [process-mno-name, resource-did]
        # invokes acquire template for every entry in resources list
        # waits for them to succeed and publishes status success for the
        # service owner to consume
        template: acquire
        arguments:
          parameters:
          - name: product_id
            # use local id which is fine
            value: "{{workflow.parameters.product_id}}"
          - name: resource_did
            # 3rd party selected Edge resource
            value: "{{tasks.resource-did.outputs.result}}"

      - name: trigger-orchestration-scaleout
        dependencies: [acquire]
        template: trigger-orchestration
        arguments:
          parameters:
          - name: resource_owner
            # stakeholder name for the orch request to be routed to
            value: "{{tasks.process-mno-name.outputs.result}}"
          - name: product_DID
            value: "{{inputs.parameters.product_DID}}"

  - name: build-intent-query
    inputs:
      parameters:
      - name: place
      - name: cpu_max
      - name: mem_max
      - name: mem_unit
      - name: storage_max
      - name: storage_unit
    script:
      image: python:alpine3.6
      imagePullPolicy: IfNotPresent
      command: [python]
      source: |
        import sys
        # Example format: intent/$(urlencode 'storage 96 GB ram 2730 MB edge Barcelona'))
        location = {{inputs.parameters.place}}['city']

        cpu_max = str("{{inputs.parameters.cpu_max}}")

        mem_max = str("{{inputs.parameters.mem_max}}")
        mem_unit = str("{{inputs.parameters.mem_unit}}")

        storage_max = str("{{inputs.parameters.storage_max}}")
        storage_unit = str("{{inputs.parameters.storage_unit}}")

        sys.stdout.write(cpu_max + " cores" + " storage " + storage_max + " " + storage_unit + " ram " + mem_max + " " + mem_unit + " edge " +  location + " \n")

  - name: srds-service
    inputs:
      parameters:
      - name: service_ip
      - name: service_port
      - name: intent_query
      - name: place
    script:
      image: docker.pkg.github.com/5gzorro/issm/python:alpine3.6-kafka-v0.1
      imagePullPolicy: IfNotPresent
      command: [python]
      source: |
        import json
        import requests
        import sys
        import urllib
        import urllib.parse

        location = {{inputs.parameters.place}}['city']
        headers = {'Content-Type': 'application/json'}
        intent_query = str("{{inputs.parameters.intent_query}}")
        iq = urllib.parse.quote(intent_query)
        r = requests.get("http://{{inputs.parameters.service_ip}}:{{inputs.parameters.service_port}}/intent/" + iq, headers=headers)
        offers = r.json()

        location_valid_offers = []
        for e in offers:
            try:
                if e['offer_object']['place'][0]['city'] == location:
                    location_valid_offers.append(e)
            except:
                pass
        # HACK UNTIL SRSD IS FIXED
        print(location_valid_offers)

  - name: acquire
    # acquire is devided into two sub-tasks:
    # 1. the acquire operation itself
    # 2. branch to inspect acquire status and either fail the flow
    # or proceed as normal with notifying trmf with the acquired offer
    inputs:
      parameters:
      - name: product_id
      - name: resource_did
    steps:
      - - name: acquire-resource
          template: acquire-simulator
          arguments:
            parameters:
            - name: product_id
              value: "{{inputs.parameters.product_id}}"

      - - name: fail-flow
          templateRef:
            name: workflow-base
            template: fail
          when: "{{steps.acquire-resource.outputs.parameters.status}} == \"FAIL\""

      - - name: notify-trmf
          template: notify-trmf
          when: "{{steps.acquire-resource.outputs.parameters.status}} != \"FAIL\""
          arguments:
            parameters:
            - name: resource_did
              value: "{{inputs.parameters.resource_did}}"

  - name: acquire-simulator
    # simulate a resource purchase with a return of a
    # fail/success status
    inputs:
      parameters:
      - name: product_id
    script:
      image: python:alpine3.6
      imagePullPolicy: IfNotPresent
      command: [python]
      source: |
        import json
        import random
        import sys
        status = "acquire_success"
        json.dump({"product_id": "{{inputs.parameters.product_id}}", "status": status}, sys.stdout)
        with open("/tmp/status.txt", "a") as myfile:
            myfile.write(status)
    outputs:
      parameters:
      - name: status
        valueFrom:
          path: /tmp/status.txt

  - name: trigger-orchestration
    inputs:
      parameters:
      - name: resource_owner
      - name: product_DID
    steps:
      - - name: event-uuid
          templateRef:
            name: workflow-base
            template: event-uuid
      - - name: publish-to-orchestration
          templateRef:
            name: workflow-base
            template: publish-on-kafka
          arguments:
            parameters:
            - name: data
              value: |
                { "event_uuid": "{{steps.event-uuid.outputs.result}}", "transaction_uuid": "{{workflow.parameters.transaction_uuid}}",
                  "operation": "{{workflow.parameters.operation}}", "sub_operation": "submit_orchestration",
                  "scenario": "{{workflow.parameters.scenario}}", "elma_url": "{{workflow.parameters.elma_url}}",
                  "product_DID": "{{inputs.parameters.product_DID}}",
                  "service_owner": "{{workflow.parameters.service_owner}}", "service_id": "{{workflow.parameters.service_id}}",
                  "resource_owner": "{{inputs.parameters.resource_owner}}"
                }
            - name: kafka_topic
              value: "issm-in-{{inputs.parameters.resource_owner}}"

  - name: get-product-offer-from-catalog
    inputs:
      parameters:
      - name: product_id
    script:
      image: docker.pkg.github.com/5gzorro/issm/python:alpine3.6-kafka-v0.1
      imagePullPolicy: IfNotPresent
      command: [python]
      source: |
        import json
        import re
        import requests
        import sys

        REGEX = re.compile('.*([0-9]+).*')

        def find(l, predicate):
            """
            util method
            """
            results = [x for x in l if predicate(x)]
            return results[0] if len(results) > 0 else None

        headers = {'Content-Type': 'application/json'}
        r = requests.get("{{workflow.parameters.catalogue_url}}/tmf-api/productCatalogManagement/v4/productOffering/{{inputs.parameters.product_id}}",
            headers=headers)
        json.dump(r.json(), sys.stdout)
        sys.stdout.write('\n')

        try:
            category = r.json()['category'][0]['name']
            if category != "VNF":
                raise Exception('*** PO must be VNF ***')
        except:
            raise

        sla_did = r.json().get('serviceLevelAgreement', {}).get('id', "")
        sys.stdout.write('sla_did: "%s" \n' % sla_did)

        href = r.json()['productSpecification']['href']
        r = requests.get(str(href), headers=headers)
        json.dump(r.json(), sys.stdout)
        sys.stdout.write('\n')

        href = r.json()['resourceSpecification'][0]['href']
        r = requests.get(str(href), headers=headers)
        json.dump(r.json(), sys.stdout)
        sys.stdout.write('\n')

        rsc_list = r.json()[0]['resourceSpecCharacteristic']

        # 2. vCPU Requirements
        element = find(rsc_list, lambda e: e.get('name', '') == 'vCPU Requirements')
        if not element:
            raise Exception("*** Unable to find 'vCPU Requirements' ***")

        # min
        min = find(element['resourceSpecCharacteristicValue'], lambda e: e['value']['alias'] == 'min-vCPU')
        if not min:
            raise Exception("*** Unable to find 'min-vCPU' ***")
        cpu_min = min['value']['value']

        # max
        max = find(element['resourceSpecCharacteristicValue'], lambda e: e['value']['alias'] == 'max-vCPU')
        if not max:
            raise Exception("*** Unable to find 'max-vCPU' ***")
        cpu_max = max['value']['value']

        sys.stdout.write('cpu_min/max: "%s, %s" \n' % (cpu_min, cpu_max))

        # 3. Virtual Memory Requirements
        element = find(rsc_list, lambda e: e.get('name', '') == 'Virtual Memory Requirements')
        if not element:
            raise Exception("*** Unable to find 'Virtual Memory Requirements' ***")

        # min
        min = find(element['resourceSpecCharacteristicValue'], lambda e: e['value']['alias'] == 'min-virtual-memory')
        if not min:
            raise Exception("*** Unable to find 'min-virtual-memory' ***")
        mem_min = min['value']['value']
        mem_unit = min['unitOfMeasure']

        # max
        max = find(element['resourceSpecCharacteristicValue'], lambda e: e['value']['alias'] == 'max-virtual-memory')
        if not max:
            raise Exception("*** Unable to find 'max-virtual-memory' ***")
        mem_max = max['value']['value']

        sys.stdout.write('mem_min/max: "%s, %s" \n' % (mem_min, mem_max))
        sys.stdout.write('mem_unit: "%s" \n' % mem_unit)

        # 4. Storage Requirements
        element = find(rsc_list, lambda e: e.get('name', '') == 'Storage Requirements')
        if not element:
            raise Exception("*** Unable to find 'Storage Requirements' ***")

        # min
        min = find(element['resourceSpecCharacteristicValue'], lambda e: e['value']['alias'] == 'min-storage')
        if not min:
            raise Exception("*** Unable to find 'min-storage' ***")
        storage_min = min['value']['value']
        storage_unit = min['unitOfMeasure']

        # max
        max = find(element['resourceSpecCharacteristicValue'], lambda e: e['value']['alias'] == 'max-storage')
        if not max:
            raise Exception("*** Unable to find 'max-storage' ***")
        storage_max = max['value']['value']

        sys.stdout.write('storage_min/max: "%s, %s" \n' % (storage_min, storage_max))
        sys.stdout.write('storage_unit: "%s" \n' % storage_unit)

        r = requests.get("{{workflow.parameters.catalogue_url}}/tmf-api/productCatalogManagement/v4/productOfferingStatus/{{inputs.parameters.product_id}}",
            headers=headers)
        json.dump(r.json(), sys.stdout)
        sys.stdout.write('\n')
        did = r.json()['did']

        with open('/tmp/sla_did.txt', 'w') as f:
            f.write(str(sla_did))

        with open('/tmp/mem_unit.txt', 'w') as f:
            f.write(str(mem_unit))

        with open('/tmp/mem_min.txt', 'w') as f:
            f.write(str(mem_min))
        with open('/tmp/mem_max.txt', 'w') as f:
            f.write(str(mem_max))

        with open('/tmp/cpu_min.txt', 'w') as f:
            f.write(str(cpu_min))
        with open('/tmp/cpu_max.txt', 'w') as f:
            f.write(str(cpu_max))

        with open('/tmp/storage_unit.txt', 'w') as f:
            f.write(str(storage_unit))

        with open('/tmp/storage_min.txt', 'w') as f:
            f.write(str(storage_min))
        with open('/tmp/storage_max.txt', 'w') as f:
            f.write(str(storage_max))

        with open('/tmp/did.txt', 'w') as f:
            f.write(str(did))

    outputs:
      parameters:
      - name: sla_did
        valueFrom:
          path: /tmp/sla_did.txt

      - name: mem_unit
        valueFrom:
          path: /tmp/mem_unit.txt

      - name: mem_min
        valueFrom:
          path: /tmp/mem_min.txt
      - name: mem_max
        valueFrom:
          path: /tmp/mem_max.txt

      - name: cpu_min
        valueFrom:
          path: /tmp/cpu_min.txt
      - name: cpu_max
        valueFrom:
          path: /tmp/cpu_max.txt

      - name: storage_unit
        valueFrom:
          path: /tmp/storage_unit.txt

      - name: storage_min
        valueFrom:
          path: /tmp/storage_min.txt
      - name: storage_max
        valueFrom:
          path: /tmp/storage_max.txt

      - name: did
        valueFrom:
          path: /tmp/did.txt

  - name: notify-trmf
    inputs:
      parameters:
      - name: resource_did
    script:
      image: docker.pkg.github.com/5gzorro/issm/python:alpine3.6-kafka-v0.1
      imagePullPolicy: IfNotPresent
      command: [python]
      source: |
        import json
        import requests
        import sys

        def raise_for_status(r):
            http_error_msg = ''
            if 400 <= r.status_code < 500:
                http_error_msg = '%s Client Error: %s' % (r.status_code, r.reason)

            elif 500 <= r.status_code < 600:
                http_error_msg = '%s Server Error: %s' % (r.status_code, r.reason)

            return http_error_msg

        resource_did = "{{inputs.parameters.resource_did}}"
        sys.stdout.write('Input parameters. resource_did: "%s"\n' % resource_did)
        payload = {
            "offerDID": resource_did
        }

        headers = {'Content-Type': 'application/json'}
        r = requests.post("{{workflow.parameters.trmf_url}}/notify_final_selection",
            json=payload,
            headers=headers)
        sys.stdout.write('r.text [%s]\n' % r.text)
        error_msg = raise_for_status(r)
        if error_msg:
            raise Exception('%s. %s' % (error_msg, r.text))
